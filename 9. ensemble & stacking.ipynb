{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "frozen-needle",
   "metadata": {},
   "source": [
    "## 세 개 모델의 예측 값 조합\n",
    "- 확률 값의 평균\n",
    "- 최대 투표 범주 확인 (보팅)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "about-complexity",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy\n",
    "\n",
    "# 예측 확률 값의 평균을 구하는 함수\n",
    "def mean_predictions(probas):\n",
    "    \"\"\"\n",
    "    예측 확률 값의 평균을 구하는 함수\n",
    "    : param probas: 예측 확률 값. 2차원 행렬.\n",
    "    : return: 평균 확률\n",
    "    \"\"\"\n",
    "    return np.mean(probas)\n",
    "\n",
    "\n",
    "# 예측 확률 값의 최대 투표 범주를 구하는 함수\n",
    "def max_voting(preds):\n",
    "    \"\"\"\n",
    "    예측 확률 값의 최대 투표 범주를 구하는 함수\n",
    "    : param probas: 예측 확률 값. 2차원 행렬\n",
    "    : return: 최대 투표 범주\n",
    "    \"\"\"\n",
    "    idxs = np.aramax(preds, axis = 1)\n",
    "    return np.take_along_axis(preds, idxs[:, None], axis = 1)\n",
    "\n",
    "\n",
    "# 예측 확률 값의 순위를 사용\n",
    "def rank_mean(probas):\n",
    "    \"\"\"\n",
    "    예측 확률 값의  순위 평균을 구하는 함수\n",
    "    : param probas: 예측 확률 값. 2차원 행렬\n",
    "    : return: 순위 평균\n",
    "    \"\"\"\n",
    "    ranked = []\n",
    "    for i in range(probas.shape[1]):\n",
    "        rank_data = stats.rankdata(probas[:,i])\n",
    "        ranked.append(rank_data)\n",
    "        \n",
    "    ranked = np.column_stack(ranked)\n",
    "    return np.mean(ranked, axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "infinite-dress",
   "metadata": {},
   "source": [
    "## rankdata 만지기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "solar-avatar",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6. 0. 1. 2. 5. 3. 4. 7.]\n",
      "[7. 1. 2. 3. 6. 4. 5. 8.]\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import rankdata\n",
    "import scipy\n",
    "\n",
    "a = np.array([ 5, 0.3,  0.4, 1, 4, 2, 3, 42])\n",
    "\n",
    "# empty_like() : 주어진 데이터와 같은 형태를 갖는 것을 만듦\n",
    "almost_ranks = np.empty_like(a)\n",
    "\n",
    "# argsort() : 정렬된 행렬의 인덱스를 반환\n",
    "almost_ranks[np.argsort(a)] = np.arange(len(a))\n",
    "print(almost_ranks)\n",
    "print(scipy.stats.rankdata(a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "compact-testament",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from functools import partial\n",
    "from scipy.optimize import fmin\n",
    "from sklearn import metrics\n",
    "\n",
    "class OptimizeAUC:\n",
    "    \"\"\"\n",
    "    AUC를 최적화하는 클래스\n",
    "    \n",
    "    약간의 변경으로 임의의 모델, 임의의 메트릭, 임의의 예측 값의 타입에 대한\n",
    "    최적의 가중치를 찾는 클래스로 만들 수 있다.\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        self.coef_ = 0\n",
    "        \n",
    "    def _auc(self, coef, X, y):\n",
    "        \"\"\"\n",
    "        AUC를 계산하고 반환하는 함수\n",
    "        : param coef: 가중치 목록, 모델의 수와 같은 길이\n",
    "        : param x: 예측 값, 2차원 행렬\n",
    "        : param y: 타겟 값, 1차원 벡터\n",
    "        \"\"\"\n",
    "        # 가중치를 각 예측 값의 열에 곱한다.\n",
    "        # 예를 들어, 첫 번째 가중치는 예측 값 행렬의 첫 번째 열에 곱하고,\n",
    "        # 두 번째 가중치는 예측 값 행렬의 두 번째 열에 곱한다.\n",
    "        x_coef = X*coef\n",
    "        \n",
    "        # 각 행의 합으로 예측 값을 생성한다.\n",
    "        predictions = np.sum(x_coef, axis = 1)\n",
    "        \n",
    "        # auc 점수를 계산한다.\n",
    "        auc_score = metrics.roc_auc_score(y, predictions)\n",
    "        \n",
    "        # 음의 auc 점수를 반환한다.\n",
    "        return -1.0 * auc_score\n",
    "        \n",
    "    def fit(self, X, y):\n",
    "        # 하이퍼파라미터 최적화 장에서 다뤘던 partial 함수이다.\n",
    "        loss_partial = partial(self._auc, X=X, y=y)\n",
    "\n",
    "        # dirichlet 분포로 가중치 초기화.\n",
    "        # 가중치의 합이 1 인 임의의 분포를 사용할 수 있다.\n",
    "        initial_coef = np.random.dirichlet(np.ones(X.shape[1]),\n",
    "                                            size=1)\n",
    "        # 손실 함수 (auc) 최적화를 위해 scipy 의 fmin 함수를 사용한다.\n",
    "        self.coef_ = fmin(loss_partial, initial_coef, disp=True)\n",
    "\n",
    "    def predict(self, X):\n",
    "        # _auc 함수와 비슷하다.\n",
    "        x_coef = X * self.coef_\n",
    "        predictions = np.sum(x_coef, axis=1)\n",
    "        return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "finished-repeat",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Roh Seung Chan\\anaconda3\\envs\\algo\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20:53:57] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Fold-2: LR AUC = 0.968479279306955\n",
      "Fold-2: RF AUC = 0.9881588496866552\n",
      "Fold-2: XGB AUC = 0.9889998918397231\n",
      "Fold-2: Average Pred AUC = 0.987911489053412\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Roh Seung Chan\\anaconda3\\envs\\algo\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20:53:59] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Fold-1: LR AUC = 0.9667666349225853\n",
      "Fold-1: RF AUC = 0.9868090862312608\n",
      "Fold-1: XGB AUC = 0.9874648479100105\n",
      "Fold-1: Average prediction AUC = 0.9862474847935611\n",
      "Optimization terminated successfully.\n",
      "         Current function value: -0.987686\n",
      "         Iterations: 62\n",
      "         Function evaluations: 130\n",
      "Optimized AUC, Fold 2 = 0.9895599732735316\n",
      "Coefficients = [-0.00144709  0.02163006  0.17085201]\n",
      "Optimization terminated successfully.\n",
      "         Current function value: -0.989600\n",
      "         Iterations: 89\n",
      "         Function evaluations: 166\n",
      "Optimized AUC, Fold 1 = 0.9876484483800279\n",
      "Coefficients = [-0.00346526  0.06029454  0.89383637]\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn import ensemble\n",
    "from sklearn import linear_model\n",
    "from sklearn import metrics\n",
    "from sklearn import model_selection\n",
    "\n",
    "# 10k 샘플과 25 개의 피쳐로 이진분류 학습 데이터를 생성한다.\n",
    "X, y = make_classification(n_samples=10000, n_features=25)\n",
    "\n",
    "# 데이터를 두 개의 폴드로 나눈다.\n",
    "xfold1, xfold2, yfold1, yfold2 = model_selection.train_test_split(\n",
    " X,\n",
    " y,\n",
    " test_size=0.5,\n",
    " stratify=y\n",
    ")\n",
    "\n",
    "# 폴드 1 데이터로 학습 후, 폴드 2 데이터에 대한 예측을 한다.\n",
    "# 로지스틱 회귀, 랜덤포레스트, xgboost 의 3 개의 모델을 학습한다.\n",
    "logreg = linear_model.LogisticRegression()\n",
    "rf = ensemble.RandomForestClassifier()\n",
    "xgbc = xgb.XGBClassifier()\n",
    "\n",
    "# 모든 모델을 폴드 1 데이터로 학습한다.\n",
    "logreg.fit(xfold1, yfold1)\n",
    "rf.fit(xfold1, yfold1)\n",
    "xgbc.fit(xfold1, yfold1)\n",
    "\n",
    "# 모든 모델을 폴드 2 데이터로 예측한다.\n",
    "# 범주 1 에 대한 예측 값(확률)들을 추출한다.\n",
    "pred_logreg = logreg.predict_proba(xfold2)[:, 1]\n",
    "pred_rf = rf.predict_proba(xfold2)[:, 1]\n",
    "pred_xgbc = xgbc.predict_proba(xfold2)[:, 1]\n",
    "\n",
    "\n",
    "## 평균 예측 값 계산\n",
    "# 가장 단순한 앙상블로 평균 예측 값을 계산한다.\n",
    "avg_pred = (pred_logreg + pred_rf + pred_xgbc)/3\n",
    "\n",
    "\n",
    "## 모든 예측 값의 2 차원 행렬\n",
    "# 4번째 열이 앙상블 평균 예측 값\n",
    "fold2_preds = np.column_stack((\n",
    " pred_logreg,\n",
    " pred_rf,\n",
    " pred_xgbc,\n",
    " avg_pred\n",
    "))\n",
    "\n",
    "\n",
    "# 개별 AUC 값을 계산하여 저장한다.\n",
    "aucs_fold2 = []\n",
    "for i in range(fold2_preds.shape[1]):\n",
    "    auc = metrics.roc_auc_score(yfold2, fold2_preds[:, i])\n",
    "    aucs_fold2.append(auc)\n",
    "    \n",
    "print(f\"Fold-2: LR AUC = {aucs_fold2[0]}\")\n",
    "print(f\"Fold-2: RF AUC = {aucs_fold2[1]}\")\n",
    "print(f\"Fold-2: XGB AUC = {aucs_fold2[2]}\")\n",
    "print(f\"Fold-2: Average Pred AUC = {aucs_fold2[3]}\")\n",
    "# 폴드를 바꾸어서 동일하게 학습/예측을 수행한다.\n",
    "# 아래와 같이 코드를 반복하는 것은 이상적이지 않다.\n",
    "# 반복되는 코드가 있다면 함수를 만들어 수행\n",
    "# 폴드 2 데이터로 학습 후, 폴드 1 데이터에 대한 예측을 한다.\n",
    "\n",
    "## 폴드 2 학습\n",
    "logreg = linear_model.LogisticRegression()\n",
    "rf = ensemble.RandomForestClassifier()\n",
    "xgbc = xgb.XGBClassifier()\n",
    "\n",
    "logreg.fit(xfold2, yfold2)\n",
    "rf.fit(xfold2, yfold2)\n",
    "xgbc.fit(xfold2, yfold2)\n",
    "\n",
    "pred_logreg = logreg.predict_proba(xfold1)[:, 1]\n",
    "pred_rf = rf.predict_proba(xfold1)[:, 1]\n",
    "pred_xgbc = xgbc.predict_proba(xfold1)[:, 1]\n",
    "avg_pred = (pred_logreg + pred_rf + pred_xgbc)/3\n",
    "\n",
    "fold1_preds = np.column_stack((\n",
    " pred_logreg,\n",
    " pred_rf,\n",
    " pred_xgbc,\n",
    " avg_pred\n",
    "))\n",
    "\n",
    "aucs_fold1 = []\n",
    "for i in range(fold1_preds.shape[1]):\n",
    "    auc = metrics.roc_auc_score(yfold1, fold1_preds[:, i])\n",
    "    aucs_fold1.append(auc)\n",
    "    \n",
    "print(f\"Fold-1: LR AUC = {aucs_fold1[0]}\")\n",
    "print(f\"Fold-1: RF AUC = {aucs_fold1[1]}\")\n",
    "print(f\"Fold-1: XGB AUC = {aucs_fold1[2]}\")\n",
    "print(f\"Fold-1: Average prediction AUC = {aucs_fold1[3]}\")\n",
    "\n",
    "\n",
    "# (위에서 만든)최적화 클래스로 최적 가중치를 찾는다.\n",
    "opt = OptimizeAUC()\n",
    "\n",
    "# 앞서 추가한 평균 예측 값을 제외하고 최적화 함수를 학습한다.\n",
    "opt.fit(fold1_preds[:, :-1], yfold1)\n",
    "opt_preds_fold2 = opt.predict(fold2_preds[:, :-1])\n",
    "auc = metrics.roc_auc_score(yfold2, opt_preds_fold2)\n",
    "print(f\"Optimized AUC, Fold 2 = {auc}\")\n",
    "print(f\"Coefficients = {opt.coef_}\")\n",
    "\n",
    "\n",
    "opt = OptimizeAUC()\n",
    "opt.fit(fold2_preds[:, :-1], yfold2)\n",
    "opt_preds_fold1 = opt.predict(fold1_preds[:, :-1])\n",
    "auc = metrics.roc_auc_score(yfold1, opt_preds_fold1)\n",
    "print(f\"Optimized AUC, Fold 1 = {auc}\")\n",
    "print(f\"Coefficients = {opt.coef_}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
