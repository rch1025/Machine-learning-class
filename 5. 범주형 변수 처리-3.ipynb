{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<=50K    24720\n",
       ">50K      7841\n",
       "Name: income, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings(action='ignore') \n",
    "\n",
    "df = pd.read_csv('adult.csv')\n",
    "\n",
    "df.income.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold = 0, AUC = 0.8794973428337469\n",
      "Fold = 1, AUC = 0.887601339079321\n",
      "Fold = 2, AUC = 0.8852609687685753\n",
      "Fold = 3, AUC = 0.8681264602321512\n",
      "Fold = 4, AUC = 0.8728581541840037\n"
     ]
    }
   ],
   "source": [
    "## ohe_logres.py -> 로지스틱 회귀 모델\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn import linear_model\n",
    "from sklearn import metrics\n",
    "from sklearn import preprocessing\n",
    "\n",
    "def run(fold):\n",
    "    \n",
    "    # 폴드 값이 있는 학습 데이터를 불러온다.\n",
    "    df = pd.read_csv(\"adult_folds.csv\")\n",
    "    \n",
    "    # 수치형 열의 목록\n",
    "    num_cols = [\n",
    "    \"fnlwgt\",\n",
    "    \"age\",\n",
    "    \"capital.gain\",\n",
    "    \"capital.loss\",\n",
    "    \"hours.per.week\"\n",
    "     ]\n",
    "    \n",
    "    # 수치형 목록을 제거한다.\n",
    "    df = df.drop(num_cols, axis=1)\n",
    "    \n",
    "    # 타겟 변수를 0 과 1 로 매핑한다.\n",
    "    target_mapping = {\n",
    "    \"<=50K\": 0,\n",
    "    \">50K\": 1\n",
    "    }\n",
    "    df.loc[:, \"income\"] = df.income.map(target_mapping)\n",
    "    \n",
    "    # income 과 kfold 열을 제외한 모든 열을 피쳐로 사용한다.\n",
    "    features = [\n",
    "    f for f in df.columns if f not in (\"kfold\", \"income\")\n",
    "    ]\n",
    "    \n",
    "    # 모든 NaN 값을 NONE 으로 채운다\n",
    "    # 모든 열을 문자열로 변환함을 주목. 범주형으로 처리할 것이므로\n",
    "    # 원래 타입이 무엇이든지 상관 없다.\n",
    "    for col in features:\n",
    "        df.loc[:, col] = df[col].astype(str).fillna(\"NONE\")\n",
    "\n",
    "    # 폴드 값으로 학습 데이터를 추출한다.\n",
    "    df_train = df[df.kfold != fold].reset_index(drop=True)\n",
    "\n",
    "    # 폴드 값으로 검증 데이터를 추출한다.\n",
    "    df_valid = df[df.kfold == fold].reset_index(drop=True)\n",
    "    \n",
    "    # scikit-learn 의 OneHotEncoder 객체를 초기화 한다.\n",
    "    ohe = preprocessing.OneHotEncoder()\n",
    "\n",
    "    # 학습 + 검증 데이터로 학습한다.\n",
    "    full_data = pd.concat(\n",
    "    [df_train[features], df_valid[features]],\n",
    "    axis=0\n",
    "    )\n",
    "    ohe.fit(full_data[features])\n",
    "\n",
    "    # 학습 데이터를 변환한다.\n",
    "    x_train = ohe.transform(df_train[features])\n",
    "\n",
    "    # 검증 데이터를 변환한다.\n",
    "    x_valid = ohe.transform(df_valid[features])\n",
    "\n",
    "    # 로지스틱 회귀 모델을 초기화 한다.\n",
    "    model = linear_model.LogisticRegression()\n",
    "\n",
    "    # 변환한 데이터로 모델을 학습한다.\n",
    "    model.fit(x_train, df_train.income.values)\n",
    "    \n",
    "    # 검증 데이터로 예측한다.\n",
    "    # AUC 를 계산할 것이므로 확률 값이 필요하다.\n",
    "    # 범주 1 의 확률을 사용한다\n",
    "    valid_preds = model.predict_proba(x_valid)[:, 1]\n",
    "    \n",
    "    # auc 값을 계산한다.\n",
    "    auc = metrics.roc_auc_score(df_valid.income.values, valid_preds)\n",
    "    \n",
    "    # auc 값을 출력한다.\n",
    "    print(f\"Fold = {fold}, AUC = {auc}\")\n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "    for fold_ in range(5):\n",
    "        run(fold_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:32:02] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Fold = 0, AUC = 0.8752407460691677\n",
      "[15:32:03] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Fold = 1, AUC = 0.8842809878805891\n",
      "[15:32:03] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Fold = 2, AUC = 0.8806773619642031\n",
      "[15:32:04] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Fold = 3, AUC = 0.866547551969817\n",
      "[15:32:04] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Fold = 4, AUC = 0.8704314857010765\n"
     ]
    }
   ],
   "source": [
    "## lbl_xgb.py -> xgboost\n",
    "\n",
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "from sklearn import metrics\n",
    "from sklearn import preprocessing\n",
    "\n",
    "def run(fold):\n",
    "    \n",
    "    # 폴드 값이 있는 학습 데이터를 불러온다.\n",
    "    df = pd.read_csv(\"adult_folds.csv\")\n",
    "    \n",
    "    # 수치형 열의 목록\n",
    "    num_cols = [\n",
    "    \"fnlwgt\",\n",
    "    \"age\",\n",
    "    \"capital.gain\",\n",
    "    \"capital.loss\",\n",
    "    \"hours.per.week\"\n",
    "     ]\n",
    "    \n",
    "    # 수치형 목록을 제거한다.\n",
    "    df = df.drop(num_cols, axis=1)\n",
    "    \n",
    "    # 타겟 변수를 0 과 1 로 매핑한다.\n",
    "    target_mapping = {\n",
    "    \"<=50K\": 0,\n",
    "    \">50K\": 1\n",
    "    }\n",
    "    df.loc[:, \"income\"] = df.income.map(target_mapping)\n",
    "    \n",
    "    # income 과 kfold 열을 제외한 모든 열을 피쳐로 사용한다.\n",
    "    features = [\n",
    "    f for f in df.columns if f not in (\"kfold\", \"income\")\n",
    "    ]\n",
    "    \n",
    "    # 모든 NaN 값을 NONE 으로 채운다\n",
    "    # 모든 열을 문자열로 변환함을 주목. 범주형으로 처리할 것이므로\n",
    "    # 원래 타입이 무엇이든지 상관 없다.\n",
    "    for col in features:\n",
    "        df.loc[:, col] = df[col].astype(str).fillna(\"NONE\")\n",
    "        \n",
    "    # 피쳐들을 레이블 인코딩한다.\n",
    "    for col in features:\n",
    "        \n",
    "        # 각 피쳐 열에 대해 LabelEncoder를 초기화 한다.\n",
    "        lbI = preprocessing.LabelEncoder()\n",
    "        \n",
    "        # 인코더를 모든 데이터로 학습한다.\n",
    "        lbI.fit(df[col])\n",
    "        \n",
    "        # 모든 데이터를 변환한다.\n",
    "        df.loc[:, col] = lbI.transform(df[col])\n",
    "\n",
    "    # 폴드 값으로 학습 데이터를 추출한다.\n",
    "    df_train = df[df.kfold != fold].reset_index(drop=True)\n",
    "\n",
    "    # 폴드 값으로 검증 데이터를 추출한다.\n",
    "    df_valid = df[df.kfold == fold].reset_index(drop=True)\n",
    "    \n",
    "    # 학습 데이터를 얻는다.\n",
    "    x_train = df_train[features].values\n",
    "    \n",
    "    # 검증 데이터를 얻는다.\n",
    "    x_valid = df_valid[features].values\n",
    "    \n",
    "    # xgb 모델을 초기화 한다.\n",
    "    model = xgb.XGBClassifier(\n",
    "    n_jobs = -1\n",
    "    )\n",
    "    \n",
    "    # 변환한 데이터로 모델을 학습한다.\n",
    "    model.fit(x_train, df_train.income.values)\n",
    "    \n",
    "    # 검증 데이터로 예측한다.\n",
    "    # AUC 를 계산할 것이므로 확률 값이 필요하다.\n",
    "    # 범주 1 의 확률을 사용한다\n",
    "    valid_preds = model.predict_proba(x_valid)[:, 1]\n",
    "    \n",
    "    # auc 값을 계산한다.\n",
    "    auc = metrics.roc_auc_score(df_valid.income.values, valid_preds)\n",
    "    \n",
    "    # auc 값을 출력한다.\n",
    "    print(f\"Fold = {fold}, AUC = {auc}\")\n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "    for fold_ in range(5):\n",
    "        run(fold_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:34:56] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Fold = 0, AUC = 0.9275682416809503\n",
      "[15:34:57] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Fold = 1, AUC = 0.9297670258940955\n",
      "[15:34:58] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Fold = 2, AUC = 0.930423614379004\n",
      "[15:34:59] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Fold = 3, AUC = 0.916908856230599\n",
      "[15:35:00] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Fold = 4, AUC = 0.9246552458969024\n"
     ]
    }
   ],
   "source": [
    "## lbl_xgb_num.py -> 앞에서 제거했던 수치형 변수들을 XGBoost에 추가\n",
    "\n",
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "from sklearn import metrics\n",
    "from sklearn import preprocessing\n",
    "\n",
    "def run(fold):\n",
    "    \n",
    "    # 폴드 값이 있는 학습 데이터를 불러온다.\n",
    "    df = pd.read_csv(\"adult_folds.csv\")\n",
    "    \n",
    "    # 수치형 열의 목록\n",
    "    num_cols = [\n",
    "    \"fnlwgt\",\n",
    "    \"age\",\n",
    "    \"capital.gain\",\n",
    "    \"capital.loss\",\n",
    "    \"hours.per.week\"\n",
    "     ]\n",
    "    \n",
    "    # 타겟 변수를 0과 1로 매핑한다.\n",
    "    target_mapping = {\n",
    "    }\n",
    "    \n",
    "    # 타겟 변수를 0 과 1 로 매핑한다.\n",
    "    target_mapping = {\n",
    "    \"<=50K\": 0,\n",
    "    \">50K\": 1\n",
    "    }\n",
    "    df.loc[:, \"income\"] = df.income.map(target_mapping)\n",
    "    \n",
    "    # income 과 kfold 열을 제외한 모든 열을 피쳐로 사용한다.\n",
    "    features = [\n",
    "    f for f in df.columns if f not in (\"kfold\", \"income\")\n",
    "    ]\n",
    "    \n",
    "    # 모든 NaN 값을 NONE 으로 채운다\n",
    "    # 모든 열을 문자열로 변환함을 주목. 범주형으로 처리할 것이므로\n",
    "    # 원래 타입이 무엇이든지 상관 없다.\n",
    "    for col in features:\n",
    "        # 수치형 열은 인코딩하지 않는다.\n",
    "        if col not in num_cols:\n",
    "            df.loc[:, col] = df[col].astype(str).fillna('NONE')\n",
    "            \n",
    "    # 피쳐들을 레이블인코딩한다.\n",
    "    for col in features:\n",
    "        if col not in num_cols:\n",
    "            # 각 피쳐 열에 대해 LabelEncoder를 초기화 한다.\n",
    "            lbI = preprocessing.LabelEncoder()\n",
    "        \n",
    "            # 인코더를 모든 데이터로 학습한다.\n",
    "            lbI.fit(df[col])\n",
    "        \n",
    "            # 모든 데이터를 변환한다.\n",
    "            df.loc[:, col] = lbI.transform(df[col])\n",
    "        \n",
    "    # 폴드 값으로 학습 데이터를 추출한다.\n",
    "    df_train = df[df.kfold != fold].reset_index(drop=True)\n",
    "\n",
    "    # 폴드 값으로 검증 데이터를 추출한다.\n",
    "    df_valid = df[df.kfold == fold].reset_index(drop=True)\n",
    "    \n",
    "    # 학습 데이터를 얻는다.\n",
    "    x_train = df_train[features].values\n",
    "    \n",
    "    # 검증 데이터를 얻는다.\n",
    "    x_valid = df_valid[features].values\n",
    "    \n",
    "    # xgb 모델을 초기화 한다.\n",
    "    model = xgb.XGBClassifier(\n",
    "    n_jobs = -1\n",
    "    )\n",
    "    \n",
    "    # 변환한 데이터로 모델을 학습한다.\n",
    "    model.fit(x_train, df_train.income.values)\n",
    "    \n",
    "    # 검증 데이터로 예측한다.\n",
    "    # AUC 를 계산할 것이므로 확률 값이 필요하다.\n",
    "    # 범주 1 의 확률을 사용한다\n",
    "    valid_preds = model.predict_proba(x_valid)[:, 1]\n",
    "    \n",
    "    # auc 값을 계산한다.\n",
    "    auc = metrics.roc_auc_score(df_valid.income.values, valid_preds)\n",
    "    \n",
    "    # auc 값을 출력한다.\n",
    "    print(f\"Fold = {fold}, AUC = {auc}\")\n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "    for fold_ in range(5):\n",
    "        run(fold_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:36:37] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Fold = 0, AUC = 0.9281676897246613\n",
      "[15:36:40] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Fold = 1, AUC = 0.9304998508808865\n",
      "[15:36:44] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Fold = 2, AUC = 0.9285396311133676\n",
      "[15:36:47] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Fold = 3, AUC = 0.9144211082491249\n",
      "[15:36:51] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Fold = 4, AUC = 0.922588733612377\n"
     ]
    }
   ],
   "source": [
    "## lbl_xgb_num_feat.py -> 범주형 변수를 가지고 2차원 조합 구하기\n",
    "\n",
    "import itertools\n",
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "from sklearn import metrics\n",
    "from sklearn import preprocessing\n",
    "\n",
    "\n",
    "def feature_engineering(df, cat_cols):\n",
    "    \"\"\"\n",
    "    피쳐 가공을 위한 함수\n",
    "    :param df: 학습/시험 데이터가 있는 pandas 데이터프레임\n",
    "    :param cat_cols: 범주형 변수의 목록\n",
    "    :return: 새 피쳐를 포함한 데이터프레임\n",
    "    \"\"\"\n",
    "    # 아래 코드는 목록의 값들의 2 차원 조합을 생성한다.\n",
    "    # 예를 들어:\n",
    "    # list(itertools.combinations([1,2,3], 2)) ->\n",
    "    # [(1, 2), (1, 3), (2, 3)]\n",
    "    combi = list(itertools.combinations(cat_cols, 2))\n",
    "    for c1, c2 in combi:\n",
    "        df.loc[\n",
    "        :,\n",
    "        c1 + \"_\" + c2\n",
    "        ] = df[c1].astype(str) + \"_\" + df[c2].astype(str)\n",
    "    return df\n",
    "\n",
    "\n",
    "def run(fold):\n",
    "    \n",
    "    # 폴드 값이 있는 학습 데이터를 불러온다.\n",
    "    df = pd.read_csv(\"adult_folds.csv\")\n",
    "    \n",
    "    # 수치형 열의 목록\n",
    "    num_cols = [\n",
    "    \"fnlwgt\",\n",
    "    \"age\",\n",
    "    \"capital.gain\",\n",
    "    \"capital.loss\",\n",
    "    \"hours.per.week\"\n",
    "     ]\n",
    "    \n",
    "    # 타겟 변수를 0과 1로 매핑한다.\n",
    "    target_mapping = {\n",
    "    }\n",
    "    \n",
    "    # 타겟 변수를 0 과 1 로 매핑한다.\n",
    "    target_mapping = {\n",
    "    \"<=50K\": 0,\n",
    "    \">50K\": 1\n",
    "    }\n",
    "    df.loc[:, \"income\"] = df.income.map(target_mapping)\n",
    "    \n",
    "    # 피쳐 가공을 위한 범주형 변수의 목록\n",
    "    cat_cols = [\n",
    "    c for c in df.columns if c not in num_cols\n",
    "    and c not in (\"kfold\", \"income\")\n",
    "    ]\n",
    "    \n",
    "    # 새 피쳐를 추가한다.\n",
    "    df = feature_engineering(df, cat_cols)\n",
    "    \n",
    "    # kfold와 income 열을 제외한 모든 열을 피쳐로 사용한다.\n",
    "    features = [\n",
    "        f for f in df.columns if f not in ('kfold', 'income')\n",
    "    ]\n",
    "    \n",
    "    # 모든 NaN 값을 NONE 으로 채운다\n",
    "    # 모든 열을 문자열로 변환함을 주목. 범주형으로 처리할 것이므로\n",
    "    # 원래 타입이 무엇이든지 상관 없다.\n",
    "    for col in features:\n",
    "        # 수치형 열은 인코딩하지 않는다.\n",
    "        if col not in num_cols:\n",
    "            df.loc[:, col] = df[col].astype(str).fillna('NONE')\n",
    "            \n",
    "    # 피쳐들을 레이블인코딩한다.\n",
    "    for col in features:\n",
    "        if col not in num_cols:\n",
    "            # 각 피쳐 열에 대해 LabelEncoder를 초기화 한다.\n",
    "            lbI = preprocessing.LabelEncoder()\n",
    "        \n",
    "            # 인코더를 모든 데이터로 학습한다.\n",
    "            lbI.fit(df[col])\n",
    "        \n",
    "            # 모든 데이터를 변환한다.\n",
    "            df.loc[:, col] = lbI.transform(df[col])\n",
    "            \n",
    "    \n",
    "    # 폴드 값으로 학습 데이터를 추출한다.\n",
    "    df_train = df[df.kfold != fold].reset_index(drop=True)\n",
    "\n",
    "    # 폴드 값으로 검증 데이터를 추출한다.\n",
    "    df_valid = df[df.kfold == fold].reset_index(drop=True)\n",
    "    \n",
    "    # 학습 데이터를 얻는다.\n",
    "    x_train = df_train[features].values\n",
    "    \n",
    "    # 검증 데이터를 얻는다.\n",
    "    x_valid = df_valid[features].values\n",
    "    \n",
    "    # xgb 모델을 초기화 한다.\n",
    "    model = xgb.XGBClassifier(\n",
    "    n_jobs = -1\n",
    "    )\n",
    "    \n",
    "    # 변환한 데이터로 모델을 학습한다.\n",
    "    model.fit(x_train, df_train.income.values)\n",
    "    \n",
    "    # 검증 데이터로 예측한다.\n",
    "    # AUC 를 계산할 것이므로 확률 값이 필요하다.\n",
    "    # 범주 1 의 확률을 사용한다\n",
    "    valid_preds = model.predict_proba(x_valid)[:, 1]\n",
    "    \n",
    "    # auc 값을 계산한다.\n",
    "    auc = metrics.roc_auc_score(df_valid.income.values, valid_preds)\n",
    "    \n",
    "    # auc 값을 출력한다.\n",
    "    print(f\"Fold = {fold}, AUC = {auc}\")\n",
    "\n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "    for fold_ in range(5):\n",
    "        run(fold_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:37:33] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Fold = 0, AUC = 0.9278338680667712\n",
      "[15:37:34] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Fold = 1, AUC = 0.930528229950961\n",
      "[15:37:35] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Fold = 2, AUC = 0.92846758697411\n",
      "[15:37:36] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Fold = 3, AUC = 0.9145926726273034\n",
      "[15:37:37] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Fold = 4, AUC = 0.9226865124083615\n"
     ]
    }
   ],
   "source": [
    "## target_encoding.py -> 타겟 인코딩\n",
    "\n",
    "import copy\n",
    "import pandas as pd\n",
    "from sklearn import metrics\n",
    "from sklearn import preprocessing\n",
    "import xgboost as xgb\n",
    "\n",
    "def mean_target_encoding(data):\n",
    "    \n",
    "    # 데이터프레임을 복사한다.\n",
    "    df = copy.deepcopy(data)\n",
    "    \n",
    "    # 수치형 변수의 목록\n",
    "    num_cols = [\n",
    "    \"fnlwgt\",\n",
    "    \"age\",\n",
    "    \"capital.gain\",\n",
    "    \"capital.loss\",\n",
    "    \"hours.per.week\"\n",
    "    ]\n",
    "    \n",
    "    # 타겟 변수를 0 과 1 로 매핑한다.\n",
    "    target_mapping = {\n",
    "    \"<=50K\": 0,\n",
    "    \">50K\": 1\n",
    "    }\n",
    "    df.loc[:, \"income\"] = df.income.map(target_mapping)\n",
    "    \n",
    "    # income 과 kfold 를 제외한 모든 열들을 피쳐로 사용한다.\n",
    "    features = [\n",
    "    f for f in df.columns if f not in (\"kfold\", \"income\")\n",
    "    and f not in num_cols\n",
    "    ]\n",
    "    \n",
    "    # 모든 NaN 값을 NONE 으로 채운다\n",
    "    # 모든 열을 문자열로 변환함을 주목. 범주형으로 처리할 것이므로\n",
    "    # 원래 타입이 무엇이든지 상관 없다.\n",
    "    for col in features:\n",
    "        # 수치형 열은 인코딩하지 않는다.\n",
    "        if col not in num_cols:\n",
    "            df.loc[:, col] = df[col].astype(str).fillna('NONE')\n",
    "            \n",
    "    # 피쳐들을 레이블인코딩한다.\n",
    "    for col in features:\n",
    "        if col not in num_cols:\n",
    "            # 각 피쳐 열에 대해 LabelEncoder를 초기화 한다.\n",
    "            lbI = preprocessing.LabelEncoder()\n",
    "        \n",
    "            # 인코더를 모든 데이터로 학습한다.\n",
    "            lbI.fit(df[col])\n",
    "        \n",
    "            # 모든 데이터를 변환한다.\n",
    "            df.loc[:, col] = lbI.transform(df[col])\n",
    "            \n",
    "    # 5 개의 검증 데이터프레임을 저장할 빈 목록\n",
    "    encoded_dfs = []\n",
    "    \n",
    "    # 모든 폴드에 대해 계산한다.\n",
    "    for fold in range(5):\n",
    "    \n",
    "        # 학습 데이터와 검증 데이터를 추출한다.\n",
    "        df_train = df[df.kfold != fold].reset_index(drop=True)\n",
    "        df_valid = df[df.kfold == fold].reset_index(drop=True)\n",
    "    \n",
    "        # for all feature columns, i.e. categorical columns\n",
    "        for column in features:\n",
    "            \n",
    "            # 범주:타겟 평균의 사전을 만든다.\n",
    "            mapping_dict = dict(\n",
    "            df_train.groupby(column)[\"income\"].mean()\n",
    "            )\n",
    "                \n",
    "            # column_enc 이 평균 인코딩을 저장하는 새 열이다.\n",
    "            df_valid.loc[\n",
    "                :, column + \"_enc\"\n",
    "            ] = df_valid[column].map(mapping_dict)\n",
    "\n",
    "        # 인코딩된 검증 데이터프레임의 목록에 추가한다.\n",
    "        encoded_dfs.append(df_valid)\n",
    "\n",
    "    # 전체 데이터프레임을 생성하여 반환한다.\n",
    "    encoded_df = pd.concat(encoded_dfs, axis=0)\n",
    "    return encoded_df\n",
    "\n",
    "\n",
    "def run(df, fold):\n",
    "    # 이전과 동일한 범주를 사용한다.\n",
    "    # 폴드로 학습 데이터를 추출한다.\n",
    "    df_train = df[df.kfold != fold].reset_index(drop = True)\n",
    "    \n",
    "    # 폴드로 검증 데이러를 추출한다.\n",
    "    df_valid = df[df.kfold == fold].reset_index(drop = True)\n",
    "    \n",
    "    # income과 kfold를 제외한 모든 열들을 피쳐로 사용한다.\n",
    "    features = [\n",
    "        f for f in df.columns if f not in ('kfold', 'income')\n",
    "    ]\n",
    "    \n",
    "        # 학습 데이터를 얻는다.\n",
    "    x_train = df_train[features].values\n",
    "    \n",
    "    # 검증 데이터를 얻는다.\n",
    "    x_valid = df_valid[features].values\n",
    "    \n",
    "    # xgb 모델을 초기화 한다.\n",
    "    model = xgb.XGBClassifier(\n",
    "    n_jobs = -1\n",
    "    )\n",
    "    \n",
    "    # 변환한 데이터로 모델을 학습한다.\n",
    "    model.fit(x_train, df_train.income.values)\n",
    "    \n",
    "    # 검증 데이터로 예측한다.\n",
    "    # AUC 를 계산할 것이므로 확률 값이 필요하다.\n",
    "    # 범주 1 의 확률을 사용한다\n",
    "    valid_preds = model.predict_proba(x_valid)[:, 1]\n",
    "    \n",
    "    # auc 값을 계산한다.\n",
    "    auc = metrics.roc_auc_score(df_valid.income.values, valid_preds)\n",
    "    \n",
    "    # auc 값을 출력한다.\n",
    "    print(f\"Fold = {fold}, AUC = {auc}\")\n",
    "\n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "    # 데이터를 불러 온다.\n",
    "    df = pd.read_csv('adult_folds.csv')\n",
    "    \n",
    "    # 타겟 인코딩을 한다.\n",
    "    df = mean_target_encoding(df)\n",
    "    \n",
    "    # 5개의 폴드에 대해 학습과 검증을 수행한다.\n",
    "    for fold_ in range(5):\n",
    "        run(df, fold_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "469/469 [==============================] - 15s 25ms/step - loss: 0.5603 - val_loss: 0.4182\n",
      "Epoch 2/3\n",
      "469/469 [==============================] - 11s 24ms/step - loss: 0.4092 - val_loss: 0.3995\n",
      "Epoch 3/3\n",
      "469/469 [==============================] - 11s 24ms/step - loss: 0.4021 - val_loss: 0.3990\n",
      "0.7840415903872121\n",
      "Epoch 1/3\n",
      "469/469 [==============================] - 15s 25ms/step - loss: 0.5572 - val_loss: 0.4162\n",
      "Epoch 2/3\n",
      "469/469 [==============================] - 11s 24ms/step - loss: 0.4094 - val_loss: 0.3990\n",
      "Epoch 3/3\n",
      "469/469 [==============================] - 12s 25ms/step - loss: 0.4022 - val_loss: 0.3990\n",
      "0.7842122134771131\n",
      "Epoch 1/3\n",
      "469/469 [==============================] - 16s 27ms/step - loss: 0.5590 - val_loss: 0.4128\n",
      "Epoch 2/3\n",
      "469/469 [==============================] - 12s 26ms/step - loss: 0.4108 - val_loss: 0.3975\n",
      "Epoch 3/3\n",
      "469/469 [==============================] - 12s 25ms/step - loss: 0.4013 - val_loss: 0.3968\n",
      "0.7872995942458795\n",
      "Epoch 1/3\n",
      "469/469 [==============================] - 15s 26ms/step - loss: 0.5574 - val_loss: 0.4132\n",
      "Epoch 2/3\n",
      "469/469 [==============================] - 12s 25ms/step - loss: 0.4096 - val_loss: 0.3976\n",
      "Epoch 3/3\n",
      "469/469 [==============================] - 12s 25ms/step - loss: 0.4029 - val_loss: 0.3979\n",
      "0.7856644972053209\n",
      "Epoch 1/3\n",
      "469/469 [==============================] - 15s 26ms/step - loss: 0.5593 - val_loss: 0.4161\n",
      "Epoch 2/3\n",
      "469/469 [==============================] - 12s 25ms/step - loss: 0.4100 - val_loss: 0.3988\n",
      "Epoch 3/3\n",
      "469/469 [==============================] - 12s 25ms/step - loss: 0.4011 - val_loss: 0.3976\n",
      "0.7859307252051517\n"
     ]
    }
   ],
   "source": [
    "## entity_emebddings.py\n",
    "\n",
    "import os\n",
    "import gc\n",
    "import joblib\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import metrics, preprocessing\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow.keras import callbacks\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras import utils\n",
    "\n",
    "def create_model(data, catcols):\n",
    "    \"\"\"\n",
    "    이 함수는 엔터티 임베딩을 위해 컴파일된 tf.keras 모델을 반환한다.\n",
    "    :param data: pandas 데이터프레임\n",
    "    :param catcols: 범주형 변수의 목록\n",
    "    :return: 컴파일된 tf.keras 모델\n",
    "    \"\"\"\n",
    "    # 임베딩을 위한 입력 목록\n",
    "    inputs = []\n",
    "    \n",
    "    # 임베딩을 위한 출력 목록\n",
    "    outputs = []\n",
    "    \n",
    "    # 모든 범주형 변수에 대해 계산\n",
    "    for c in catcols:\n",
    "        # 각 열의 유일 값의 수를 찾는다.\n",
    "        num_unique_values = int(data[c].nunique())\n",
    "        # 간단한 임베딩 사이즈 계산 방법\n",
    "        #최소 값은 유일 값 수의 절반\n",
    "        # 최대 값은 50. 최대 값 역시 유일 값의 수에 따라 다를 수 있지만\n",
    "        # 50 이면 대부분의 경우 충분하다.\n",
    "        # 유일 값의 개수가 수백 만이라면 더 높은 값이 필요할 것이다.\n",
    "        embed_dim = int(min(np.ceil((num_unique_values)/2), 50))\n",
    "    \n",
    "        # 사이즈 1 의 간단한 케라스 입력 레이어\n",
    "        inp = layers.Input(shape=(1,))\n",
    "    \n",
    "        # 원래 입력에 임베딩 레이어를 추가한다.\n",
    "        # 임베딩의 크기는 언제나 입력의 유일 값의 수 + 1 이다.\n",
    "        out = layers.Embedding(\n",
    "        num_unique_values + 1, embed_dim, name=c\n",
    "        )(inp)\n",
    "\n",
    "        # 1 차원 공간 드롭아웃은 임베딩 레이어에서 표준이다.\n",
    "        # NLP 에서도 사용할 수 있다.\n",
    "        out = layers.SpatialDropout1D(0.3)(out)\n",
    "    \n",
    "        # 입력의 차원을 임베딩에 맞게 변경한다.\n",
    "        # 이 레이어가 현재 피쳐의 출력 레이어가 된다.\n",
    "        out = layers.Reshape(target_shape=(embed_dim, ))(out)\n",
    "    \n",
    "        # 입력을 입력 목록에 추가한다.\n",
    "        inputs.append(inp)\n",
    "        \n",
    "        # 출력을 출력 목록에 추가한다.\n",
    "        outputs.append(out)\n",
    "        \n",
    "    # 모든 출력을 연결한다.\n",
    "    x = layers.Concatenate()(outputs)\n",
    "    \n",
    "    # 배치놈 레이어를 추가한다.\n",
    "    # 여기서부터는 원하는데로 신경망 구조를 변경할 수 있다.\n",
    "    # 아래는 내가 선호하는 구조이다.\n",
    "    # 수치형 변수가 있다면 여기나 이전 concatenate()에 추가하면 된다.\n",
    "    x = layers.BatchNormalization()(x)\n",
    "\n",
    "    # 몇 개의 밀집 레이어를 드롭아웃과 함께 추가한다.\n",
    "    # 1 개 혹은 2 개의 밀집 레이어로 시작하는 것이 좋다.\n",
    "    x = layers.Dense(300, activation=\"relu\")(x)\n",
    "    x = layers.Dropout(0.3)(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "\n",
    "    x = layers.Dense(300, activation=\"relu\")(x)\n",
    "    x = layers.Dropout(0.3)(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "\n",
    "    # 소프트멕스 활성 함수를 사용하여 두 개의 범주를 예측한다.\n",
    "    # 이진 분류의 경우 시그모이드 활성함수를 사용하여 한 개의 값만\n",
    "    # 출력할 수도 있다.\n",
    "    y = layers.Dense(2, activation=\"softmax\")(x)\n",
    "    \n",
    "    # 마지막 모델을 생성한다.\n",
    "    model = Model(inputs=inputs, outputs=y)\n",
    "    \n",
    "    # 모델을 컴파일 한다.\n",
    "    # 아담 최적화 함수와 이진 교차 엔트로피 손실 함수를 사용한다.\n",
    "    # 다른 최적화 함수와 손실 함수를 시도해보고 모델 성능을 비교해 보라.\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam')\n",
    "    return model\n",
    "\n",
    "\n",
    "def run(fold):\n",
    "    # 폴드 값이 있는 학습 데이터를 불러 온다.\n",
    "    df = pd.read_csv(\"cat_train_folds.csv\")\n",
    "    # id, target, kfold 열을 제외한 모든 열을 피쳐로 사용한다.\n",
    "    features = [\n",
    "         f for f in df.columns if f not in (\"id\", \"target\", \"kfold\")\n",
    "        ]\n",
    "    \n",
    "    # 모든 NaN 값을 NONE 으로 채운다.\n",
    "    # 모든 열을 문자열로 변환함을 주목하라. 범주형으로 처리할 것이므로\n",
    "    # 원래 타입이 무엇이든지 상관 없다\n",
    "    for col in features:\n",
    "        df.loc[:, col] = df[col].astype(str).fillna(\"NONE\")\n",
    "    \n",
    "    # 각각의 피쳐를 레이블인코딩한다.\n",
    "    # 실무에서는 레이블인코더를 모두 저장해야 한다.\n",
    "    for feat in features:\n",
    "        lbl_enc = preprocessing.LabelEncoder()\n",
    "        df.loc[:, feat] = lbl_enc.fit_transform(df[feat].values)\n",
    "\n",
    "    # 폴드로 학습 데이터를 추출한다.\n",
    "    df_train = df[df.kfold != fold].reset_index(drop=True)\n",
    "    \n",
    "    # 폴드로 검증 데이터를 추출한다.\n",
    "    df_valid = df[df.kfold == fold].reset_index(drop=True)\n",
    "    \n",
    "    # tf.keras 모델을 생성한다.\n",
    "    model = create_model(df, features)\n",
    "    \n",
    "    # 피쳐는 목록의 목록에 저장되어 있다.\n",
    "    xtrain = [\n",
    "        df_train[features].values[:, k] for k in range(len(features))\n",
    "    ]\n",
    "    \n",
    "    xvalid = [\n",
    "        df_valid[features].values[:, k] for k in range(len(features))\n",
    "    ]\n",
    "    \n",
    "    # 타겟 변수를 추출한다.\n",
    "    ytrain = df_train.target.values\n",
    "    yvalid = df_valid.target.values\n",
    "    \n",
    "    # 타겟 변수를 이진화를 적용해 범주로 변환한다.\n",
    "    ytrain_cat = utils.to_categorical(ytrain)\n",
    "    yvalid_cat = utils.to_categorical(yvalid)\n",
    "\n",
    "    # 모델을 학습한다.\n",
    "    model.fit(xtrain,\n",
    "            ytrain_cat,\n",
    "            validation_data=(xvalid, yvalid_cat),\n",
    "            verbose=1,\n",
    "        batch_size=1024,\n",
    "        epochs=3\n",
    "        )\n",
    "\n",
    "    # 검증 예측을 생성한다.\n",
    "    valid_preds = model.predict(xvalid)[:, 1]\n",
    "    # auc 값을 계산하여 출력한다.\n",
    "    print(metrics.roc_auc_score(yvalid, valid_preds))\n",
    "    # GPU 메모리를 반환한다.\n",
    "    K.clear_session()\n",
    "    \n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "    run(0)\n",
    "    run(1)\n",
    "    run(2)\n",
    "    run(3)\n",
    "    run(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
